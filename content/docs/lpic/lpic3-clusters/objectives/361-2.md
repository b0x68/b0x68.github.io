---
title: "361.2 Load Balanced Clusters (weight: 8)"
#bookCollapseSection: true
---

# Tech Tutorial: 361.2 Load Balanced Clusters (weight: 8)

## Introduction

In today's digital environment, where high availability and scalability are imperative for most applications, understanding how to set up load balanced clusters is crucial. This tutorial aims to explore the concept of load balancing within clusters, focusing on Linux environments. We will cover key knowledge areas pertinent to deploying and managing load balanced clusters using common Linux utilities and tools.

## Key Knowledge Areas

- Concepts of load balancing
- Load balancing algorithms
- HAProxy
- Keepalived
- LVS (Linux Virtual Server)
- Configuring and managing load balanced clusters

## Utilities

- `haproxy`
- `keepalived`
- `ipvsadm`

## Step-by-Step Guide

### 1. Understanding Load Balancing Concepts

Load balancing is the process of distributing network or application traffic across multiple servers. This distribution helps in achieving optimal resource utilization, maximizing throughput, minimizing response time, and avoiding overload of any single resource.

### 2. Load Balancing Algorithms

Before setting up a load balancer, it's essential to understand the different algorithms available:
- **Round Robin**: Requests are distributed across the group of servers sequentially.
- **Least Connection**: Directs traffic to the server with the fewest active connections.
- **Source IP Hash**: Determines which server to use based on a hash of the source IP address.

### 3. Setting up HAProxy

HAProxy is a free, very fast, and reliable solution offering high availability, load balancing, and proxying for TCP and HTTP-based applications.

#### Installation:

```bash
sudo apt-get update
sudo apt-get install haproxy
```

#### Configuration:

Edit `/etc/haproxy/haproxy.cfg` to configure the basics of load balancing:

```config
global
    log /dev/log local0
    maxconn 2000
    user haproxy
    group haproxy

defaults
    log global
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

frontend http_front
    bind *:80
    stats uri /haproxy?stats
    default_backend http_back

backend http_back
    balance round-robin
    server server1 192.168.0.101:80 check
    server server2 192.168.0.102:80 check
```

#### Running HAProxy:

```bash
sudo systemctl start haproxy
sudo systemctl enable haproxy
```

### 4. Using Keepalived for High Availability

Keepalived implements a set of checkers to dynamically and adaptively maintain and manage load balanced server pool according their health.

#### Installation:

```bash
sudo apt-get install keepalived
```

#### Configuration:

Create or edit `/etc/keepalived/keepalived.conf`:

```config
vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.0.200
    }
}
```

#### Running Keepalived:

```bash
sudo systemctl start keepalived
sudo systemctl enable keepalived
```

### 5. Managing Linux Virtual Server (LVS) with `ipvsadm`

Linux Virtual Server manages load balancing with a variety of scheduling algorithms.

#### Installation:

```bash
sudo apt-get install ipvsadm
```

#### Configuration:

```bash
# Add a virtual service
sudo ipvsadm -A -t 192.168.0.200:80 -s rr

# Add real servers to the virtual service
sudo ipvsadm -a -t 192.168.0.200:80 -r 192.168.0.101:80 -m
sudo ipvsadm -a -t 192.168.0.200:80 -r 192.168.0.102:80 -m
```

#### Managing LVS:

```bash
# Listing the virtual servers
sudo ipvsadm -L -n

# Removing a virtual service
sudo ipvsadm -D -t 192.168.0.200:80
```

## Conclusion

Setting up a load balanced cluster involves understanding the underlying concepts and choosing the appropriate tools and algorithms. In this tutorial, we've seen how to configure HAProxy for load balancing, Keepalived for high availability, and LVS for advanced load management. With these tools, you can ensure your applications are both scalable and reliable.

This setup provides a robust foundation, but always remember to tailor configurations and choice of tools to your specific use case and environment for optimal performance.